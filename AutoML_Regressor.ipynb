{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML library to get good regressor for the dataset\n",
    "\n",
    "   ## Library can handle following:\n",
    "       1. Deal with missing values in data-set\n",
    "       2. Scaling for numerical values\n",
    "       3. Encoding for categorical values\n",
    "       4. Feature selection through F-test (ANOVA)\n",
    "   ## The library can give a tuned model by evaluating following regressors:\n",
    "       1. Linear Regression\n",
    "       2. Random Forest Regression\n",
    "       3. XG Boost Regression\n",
    "       4. Elastic Net Regression\n",
    "   ## Cross-validation is used to prevent over-fitting on training set\n",
    "   ## Scoring function to select model is Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Class containing code to find the best model\n",
    "\n",
    "class AutoML_Regressor:\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "\n",
    "        categories = []\n",
    "        \n",
    "        categorical_columns = X_train.select_dtypes(include = ['category','bool', 'object'])\n",
    "\n",
    "        for i in range(categorical_columns.shape[1]):\n",
    "            categories.append(list(categorical_columns.iloc[:,i].dropna().unique()))\n",
    "\n",
    "        preprocessor = ColumnTransformer([\n",
    "          ('numerical', Pipeline([('cleaner', SimpleImputer()), ('scaler', StandardScaler())]), make_column_selector(dtype_exclude=['object','category','bool'])),\n",
    "          ('categorical', Pipeline([('cleaner', SimpleImputer(strategy = 'most_frequent')), ('encoder', OneHotEncoder(sparse = False, categories=categories))]), make_column_selector(dtype_include=['object','category','bool']))\n",
    "        ])\n",
    "\n",
    "        model_pipeline_step = []\n",
    "        model_pipeline_step.append(('preprocessor',preprocessor))\n",
    "        model_pipeline_step.append(('feature_selector',SelectKBest(f_regression,k='all')))\n",
    "        model_pipeline_step.append(('estimator',LinearRegression()))\n",
    "        model_pipeline = Pipeline(model_pipeline_step)\n",
    "\n",
    "        features = preprocessor.fit_transform(X_train).shape[1]\n",
    "\n",
    "        optimization_grid = []\n",
    "\n",
    "        # Linear regression\n",
    "        optimization_grid.append({\n",
    "            'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
    "            'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "            'feature_selector__k': list(np.arange(1,features,5)),\n",
    "            'estimator':[LinearRegression()]})\n",
    "\n",
    "        # Random Forest Regressor\n",
    "        optimization_grid.append({\n",
    "        'preprocessor__numerical__scaler':[None],\n",
    "        'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "        'feature_selector__k': list(np.arange(1,features,5)),\n",
    "        'estimator':[RandomForestRegressor(random_state=0)],\n",
    "        'estimator__n_estimators':np.arange(5,1000,20),\n",
    "        'estimator__criterion':['gini','entropy'],\n",
    "        'estimator__max_depth': [2, 4, 6, 8, 10],\n",
    "        'estimator__min_samples_split': [2, 5, 10, 15, 100],\n",
    "        'estimator__min_samples_leaf': [1, 2, 5, 10]})\n",
    "\n",
    "        # XG Boost\n",
    "        optimization_grid.append({\n",
    "            'preprocessor__numerical__scaler':[None],\n",
    "            'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "            'feature_selector__k': list(np.arange(1,features,5)),\n",
    "            'estimator':[GradientBoostingRegressor(random_state=0)],\n",
    "            'estimator__n_estimators':np.arange(5,1000,20),\n",
    "            'estimator__learning_rate':np.linspace(0.1,0.9,20),\n",
    "            'estimator__subsample': [0.9, 0.5, 0.2, 0.1],\n",
    "            'estimator__max_depth': [2, 4, 6, 8, 10]})\n",
    "        \n",
    "        # Elastic Net Regression\n",
    "        optimization_grid.append({\n",
    "            'preprocessor__numerical__scaler':[RobustScaler(),StandardScaler(),MinMaxScaler()],\n",
    "            'preprocessor__numerical__cleaner__strategy':['mean','median'],\n",
    "            'feature_selector__k': list(np.arange(1,features,5)),\n",
    "            'estimator':[ElasticNet(random_state = 0)],\n",
    "            'estimator__alpha': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0],\n",
    "            'estimator__l1_ratio': np.arange(0, 1, 0.01)})\n",
    "\n",
    "        search = RandomizedSearchCV(model_pipeline, optimization_grid, n_iter=250, scoring = 'neg_root_mean_squared_error', n_jobs = -1, random_state = 0, verbose = 3, cv = 10)\n",
    "\n",
    "        search.fit(X_train, y_train)\n",
    "        self.best_estimator_ = search.best_estimator_\n",
    "        self.best_pipeline = search.best_params_\n",
    "        self.optimization_grid = optimization_grid\n",
    "        self.model_pipeline = model_pipeline\n",
    "\n",
    "    def predict(self,X,y = None):\n",
    "        return self.best_estimator_.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example for choosing best regressor for the Boston House prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston2 = pd.DataFrame(boston['data'], columns = boston['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  \n",
       "5     18.7  394.12   5.21   28.7  \n",
       "6     15.2  395.60  12.43   22.9  \n",
       "7     15.2  396.90  19.15   27.1  \n",
       "8     15.2  386.63  29.93   16.5  \n",
       "9     15.2  386.71  17.10   18.9  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston2['PRICE'] = boston['target']\n",
    "boston2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston2['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston2.iloc[:, 0:len(boston2.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the defined above to create a model\n",
    "model = AutoML_Regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 250 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 304 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 816 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1200 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1616 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2128 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2500 out of 2500 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Fitting model on the training data-set\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8892444983177056"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking R2 score for best regressor\n",
    "r2_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessor__numerical__scaler': None,\n",
       " 'preprocessor__numerical__cleaner__strategy': 'median',\n",
       " 'feature_selector__k': 11,\n",
       " 'estimator__subsample': 0.5,\n",
       " 'estimator__n_estimators': 405,\n",
       " 'estimator__max_depth': 2,\n",
       " 'estimator__learning_rate': 0.14210526315789473,\n",
       " 'estimator': GradientBoostingRegressor(learning_rate=0.14210526315789473, max_depth=2,\n",
       "                           n_estimators=405, random_state=0, subsample=0.5)}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the best regressor as determined by the AutoML_Regressor library\n",
    "model.best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting model predictions for plotting\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing actual test datset results in np array for plotting\n",
    "actual = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting actual vs predicted prices to see if the resulting trend is linear\n",
    "plt.plot(predictions, actual, 'o')\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
